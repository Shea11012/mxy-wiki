---
tags: []
date created: 2022-03-15 17:56
date modified: 2023-05-20 00:47
title: 避免消息丢失
---

## 生产者如何保证消息的可靠性

**acks 参数**
- acks=0，producer 不等待 broker 响应，效率最高，但是消息可能会丢
- acks=1，leader broker 收到消息后，不等待其他 follower 响应，立即返回 ack。此时其他 follower 还没收到 leader 同步消息 leader 挂了，那么消息丢失
- acks=-1，leader broker 收到消息，挂起，等待所有 ISR 列表中的 follower 返回结果后，再返回 ack。

根据不同的场景设置：
- 需要严格保证消息不丢失，设置为 -1
- 允许存在丢失，设置 1
- 不在乎消息丢失，设置 0

**retries 参数**：如果生产者在发送消息的时候发生了错误，可以通过设置 retries 参数来设置生产者重试次数。这样可以在发生网络问题或 kafka 服务暂不可用的情况下，生产者可以尝试再次发送消息。
**`max.in.flight.requests.per.connection` 参数**：设置为 1，这样生产者在得到一个请求的确认信号前，不会发送下一个请求。可以避免重新发送消息时导致的消息顺序混乱。

## kafka 为什么不支持读写分离

kafka 为了避免数据不一致的问题，采用通过主节点来统一提供服务的方式。
不支持读写分离的原因：
- 场景不一致：读写分离是针对读操作负载很大，但写操作负载不高的场景。kafka 不适合这种场景。
- 延迟问题：kafka 通过 pull 方式来实现数据同步，因此 leader 与 follower 副本之间存在数据不一致的情况，如果允许 follower 提供读服务，就会带来消息滞后的问题。

## kafka 能否手动删除消息

kafka 存储日志结构中每一个分区副本都对应一个 log，log 又可以分为多个 logSegment，这样便于 kafka 对日志的清理操作。
- 普通消息：使用 kafka-delete-records 或调用 API `Admin.deleteRecords` 删除消息
- 设置 key 且参数 `cleanup.policy=delete/campact`，可以依靠 log cleaner 组件提供的功能删除该 key 消息
	- 日志删除，按照一定的保留策略直接删除不符合条件的日志分段
	- 日志压缩，针对每个消息的 key 进行整合，对于有相同 key 的不同 value 值，只保留最后一个版本
