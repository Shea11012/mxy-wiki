---
tags:
  - elasticsearch
date created: 2023-10-08 18:18
date modified: 2023-10-11 04:19
---
---
# 文档的基本 crud 与批量操作

Create 一个文档

```
PUT users/_create/1
POST users/_doc
两者的区别是：
- put指定文档ID，如果文档存在，则操作失败
- post系统自动生产ID
```

Get 一个文档

```
Get index/type/id
```

Index 文档

```
PUT index/_doc/1
index 和 create 区别：如果文档不存在，就索引新的文档。否则现有文档会被删除，新的文档被索引。版本信息+1
```

Bulk API

```
POST _bulk
```

支持在一次 API 调用中，对不同的索引进行操作

支持四种类型：index、create、update、delete

操作中单条失败不会影响其他操作

返回结果包括了每一条操作执行的结果

mget

```
GET _mget
```

批量操作，可以减少网络连接所产生的开销

\_msearch

批量查询

```
POST index/_msearch
```

# URI Search 通过 URI query 实现搜索

>[!note]
> GET /index/\_search?q=2012&df=title&sort=year:desc&from=o&size=10&timeout=1s
> - q 指定查询语句
> - df 默认字段，不指定时会对所有字段进行查询
> - sort 排序，from 和 size 分页
> - profile 可以查看查询是如何被执行的

## 泛查询与指定字段查询

```
GET /index/_search?q=2012  # 泛查询
GET /index/_search?q=2012&df=title  # 指定字段查询
```

## Term 和 Phrase

```
GET /index/_search?q=title:"a b" // pharse 查询，表示要按照 a b 的顺序查询
GET /index/_search?q=title:(a b) // 分组查询，表示要包含 a 或 b
```

## 查询操作符

```
AND、OR、NOT 或者 && 、||、!
必须大写
title:(a NOT b)

分组
+ 表示 must
- 表示 must_not
例：title:(+a -b) 表示必须包含a 不包含b

范围查询
区间：[]闭区间，{}开区间
year:{2019 TO 2018}
year:[* TI 2018]

算数符号
year:>2010
year:(>2010 && <=2018)
year:(+>2010 +<=2018)

通配符查询（通配符查询效率低，占用内存大）
？ 代表1个字符 * 代表 0 或多个字符
title:mi?d
title:be*

正则表达
title: [bt]oy

模糊匹配与近似查询
title:befutifl~1
title:"lord rings"~2
```

# Request Body Search

## 检查文档是否存在

`HEAD /index/type/id`

HEAD 方式只会返回 HTTP 头，不会返回响应体

## 文档局部更新

`POST /index/type/id/_update`

update 请求表单接受一个局部文档参数 `doc` 它会合并到现有文档中，存在的字段被覆盖，新字段添加

```
POST /website/blg/1/_update
{
    "doc":{
        "tag":["testing"],
        "views":0
    }
}
retry_on_conflict=5 参数表示失败重试次数
```

## 检索多个文档

```
POST /_mget
{
    "docs":[
        {
            "_index":"website",
            "_type":"blog",
            "_id":2,
        },
        {
            "_index":"website",
            "_type":"pageviews",
            "_id":1,
            "_source":"view" // 指定检索字段
        }
    ]
}
如果文档具有相同的 _index 和 _type 可以通过 ids 数组来代替完整的 docs 数组
POST /index/type/_mget
{
    "ids":["2","1"]
}
```

## 分页排序

普通分页，`index.max_result_window` 限制分页深度，默认为 10000
```http
GET /book/_search
{
	"query": {
		"match": {
			"author": "金庸"
		}
	},
	"from": 0,
	"size": 5,
	"sort": [
		{
			"price":{
				"order": "desc"
			}
		}
	]
}
```

深度分页，需要有 `query` 和 `sort` 两个参数
```http
POST index/_search
{
	"size": 1,
	"query": {
		"match_all": {}
	},
	"search_after": [	# 使用 search after 必须要确保有一个唯一排序id，如 _id， 每次使用结果集返回的最后一个 id
		12,
		"fasffhfsdf"
	],
	"sort": [
		{"age": "asc"},
		{"_id": "asc"},
	]
}
```

scroll，常用在需要全部数据时
```http
POST index/_search?scroll=5m # scroll 表示创建一个 5m 的快照，但有新数据写入以后无法被查到
{
	"size": 1,				# 创建成功后，会返回一个 scroll_id
	"query": {
		"match_all": {}
	},
}

POST  _search/scroll
{
	"scroll": "1m",
	"scroll_id": "_scroll_id"
}
```


\_source 过滤
- \_source 支持通配符
- 如果 \_source 没有存储，就只返回匹配文档的元数据

```http
GET index/_search
{
	"_source": ["order_date","category.keyword"]
	"query":{
		"match_all": {}
	}
}
```

## 多条件查询和范围查询

多条件同时成立
```http
GET /book/_search
{
	"query": {
		"bool": {
			"must": [
				{
					"match": { "author": "金庸" }
				},
				{
					"match": { "pages": 1978 }
				}
			]
		}
	}
}
```

多条件满足其一
```http
GET /book/_search
{
	"query": {
		"bool": {
			"should": [
				{
					"match": {"author": "金庸"}
				},
				{
					"match": {"pages": 1978 }
				}
			]
		}
	}
}
```

范围查询
```http
GET /book/_search
{
	"query": {
		"bool": {
			"must": [
				{
					"match": {"author": "金庸"}
				},
				{
					"range": {
						"price": {
							"gte": 50,
							"lte": 100
						}
					}
				}
			]
		}
	}
}
```

## 脚本字段

```http
GET index/_search
{
	"script_fields": {
		"new_field": {
			"script": {
				"lang": "painless",
				"source": "doc['order_date'].value + 'hello'"
			}
		}
	},
	"query": {
		"match_all": {}
	}
}
```

## 查询表达式

```
GET index/_search
{
	"query": {
		"match": {
			"comment": "last christmas" # 默认是 or
			"operator": "AND"
		}
	}
}
```

## 短语搜索

```
GET index/_search
{
	"query": {
		"match_phrase": {
			"comment": {
				"query": "a b c", # 表示必须按照顺序出现
				"slop": 1	# 设置这个值，可以使得顺序中间出现其它字段，这里允许出现一个字段
			}
		}
	}
}
```

## Query string 

```
GET index/_search
{
	"query": {
		"query_string":{
			"default_field": "name",	# 指定查询字段，等于 df，多个字段 ["a","b"]
			"query": "a AND b" 
		}
	}
}
```

## simple query string

- 类似 query string，会忽略错误的语法，同时只支持部分查询语法

- 不支持 AND OR NOT，会当做字符串处理
- Term 之间的默认关系是 OR，可以指定 operator
- 支持部分逻辑：
  - \+ 替代 AND
  - | 替代 OR
  - \- 替代 NOT

```
GET index/_search
{
	"query":{
		"simple_query_string": {
			"query": "a b",
			"fields": ["a"]
			"default_operator": "AND"
		}
	}
}
```

# Multi Match Query

## 单字符串和多字段搜索

```http
POST index/_search
{
	"query": {
		"multi_match": {
			"type": "best_fields",	// 默认的查询类型
			"query": "Quick pets",
			"fields": ["title","body"],	// 会依据这个数组内的字段，去最高分的数据
			"tie_breaker": 0.2,
			"minimum_should_match": "20%",
		}
	}
}
```

# Function Score Query

## 优化算分

```http
POST index/_search
{
	"query": {
		"function_score": {
			"query": {
				"multi_match": {
					"query": "popularity",
					"fields": ["title","content"]
				}
			},
			"field_value_factor": {	// 指定算分的函数和因子
				"field": "votes",
				"modifier": "log1p",
				"factor": 0.1
			},
			"boost_mode": "sum",
			"max_boost": 3
		}
	}
}
```

# 聚合查询 aggregation

bucket 类似 MySQL 中的 group，metric 对 bucket 执行统计操作

## Bucket Aggregation

按照一定规则，将文档分类到不同的 bucket 中。

## Metric Aggregation

- 单值分析：只输出一个分析结果
  - min，max，avg，sum
  - Cardinality （类似 distinct count）
- 多值分析：输出多个分析结果
  - stats，extended stats
  - percentile，percentile rank
  - top hits

## pipeline Aggregation

支持对聚合分析的结果，再次进行聚合分析

pipeline 的分析结果会输出到原结果中，根据位置不同，分为两类：

- sibling：结果和现有分析结果同级
  - max，min，avg，sum bucket 
  - stats，extended status bucket
  - percentiles bucket
- parent：结果内嵌到现有聚合分析结果之中
  - derivative 求导
  - cumulative sum （累计求和）
  - moving function （滑动窗口）

`size: 0` 表示只返回聚合统计结果，不返回查询的 hits 结果
```http
GET /book/_search
{
	"aggs": {
		"author_agg_name": {
			"terms": {
				"field": "author"
			}
		}
	},
	"size": 0
}
```

# 嵌套对象 & 父子文档

>[!tip]
> es 并不擅长处理关联关系，一般采用：
> - 对象类型
> - 嵌套对象
> - 父子关联关系
> - 应用端关联

## 父子文档

```http
PUT index
{
	"settings": {
		"number_of_shards": 2,
	},
	"mappings": {
		"properties": {
			"blog_comments_relation": {
				"type": "join",	# 通过 join 指定父子文档
				"relations": {
					"blog": "comment"	# 父文档 blog 子文档 comment
				}
			},
			"content": {
				"type": "text
			},
			"title": {
				"type": "keyword"
			}
		}
	}
}

// 索引父文档
PUT index/_doc/blog1
{
	"title": "learning es",
	"content": "learning es",
	"blog_comments_relation": {
		"name": "blog"	# 指定 blog 表示创建的是父文档
	}
}

// 索引子文档
PUT index/_doc/comment1?routing=blog1 # 加上 routing 确保父子文档在同一分片上
{
	"comment": "子文档",
	"username": "shea",
	"blog_comments_relation": {
		"name": "comment", // 指定 comment 表示创建的是子文档
		"parent": "blog1"	// 父文档是 blog1
	}
}

// 根据父文档id查询评论
POST index/_search
{
	"query": {
		"parent_id": {
			"type": "comment",	# 指定查询类型
			"id": "blog1"	# 指定父文档id
		}
	}
}

// 根据子文档查询父文档
POST index/_search
{
	"query": {
		"has_child": {
			"type": "comment",
			"query": {
				"match": {
					"username": "shea" # 查询子文档中有名字为 shea 的父文档
				}
			}
		}
	}
}

// has parent，返回相关的子文档
POST index/_search
{
	"query": {
		"has_parent": {
			"parent_type": "blog",
			"query": {
				"match": {
					"title": "learning es" # 查询父文档 blog 中标题包含 learning es 的子文档
				}
			}
		}
	}
}

// 访问子文档，通过子文档id和父文档id. 更新同理
GET index/_doc/{child id}?routing={parent id}
```



|      | nested object                      | parent / Child                         |
| ---- | ---------------------------------- | -------------------------------------- |
| 优点 | 文档存储在一起，读取性能高         | 父子文档可以独立更新                   |
| 缺点 | 更新嵌套子文档时，需要更新整个文档 | 需要额外的内存维护关系。读取性能相对差 |
| 场景 | 读居多，子文档偶尔更新，以查询为主 | 写，子文档更新频繁                     |

# 重建索引

重建索引情况：

- 索引的 mapping 发生变更：字段类型更改，分词器及字典更新
- 索引的 settings 发生变更：索引的主分片数发生改变
- 集群内，集群间需要做数据迁移

## Update By Query

update by query：在现有索引上重建

```http
// 如果对 index 上的字段添加了一个分词器，可以直接调用这个 api 对索引进行重建
POST index/_update_by_query 

---------------------------------------------

// 更改已有字段类型的 mappings 只能使用 reindex
// 旧索引 A
// 创建 A_1 索引
PUT A_1/
{
	"mappings": {
		"properties": {
			"content": {
				"type": "text",
				"fields": {
					"english": {
						"type": "text",
						"analyzer": "english",
					}
				}
			},
			"keyword": {
				"type": "keyword",
			}
		}
	}
}
```

## Reindex

reindex：在其他索引上重建索引
```http
// reindex 索引
POST _reindex
{
	"source": {
		"index": "old_index"
	},
	"dest": {
		"index": "new_index"
	}
}
```

**当使用 reinex 迁移大量数据时，速度变慢的优化：**
- 批量写入值太小。结合堆内存、线程池调整大小
- reindex 是 scroll 实现，提高 scroll 并行度

提高批量写入值
```http
PUT _reindex
{
	"source": {
		"index": "source",
		"size": 5000
	},
	"dest": {
		"index": "dest"
	}
}
```

提高 scroll 并行度，当 slices 数量等于索引中分片数量时，性能最高
```http
// 自动设置分片
POST _reindex?slices=5&refresh
{
	"source": {
		"index": "old"
	},
	"dest": {
		"index": "new"
	}
}
```

# Ingest Node & PainlessScript

## Ingest Node

默认配置下，每个节点都是 ingest node。

具有预处理数据的能力，可拦截 index 或 bulk api 的请求

对数据进行转换，并重新返回给 index 或 bulk api

```http
POST _ingest/pipeline/_simulate   // 使用 simulate api 模拟 pipeline，模拟了一组processors，在docs中添加了一组测试数据
{
	"pipeline": {
		"description": "split tags",
		"processors": [
			{
				"split": {
					"field": "tags",
					"separator": ","
				}
			}
		]
	},
	"docs": [
		{
			"_index": "index",
			"_id": "id",
			"_source": {
				"tags":"go,python,java,php,javascript"
			}
		}
	]
}
```


|                | Logstash                                   | Ingest Node                            |
| -------------- | ------------------------------------------ | -------------------------------------- |
| 数据输入与输出 | 支持从不同的数据源读取，并写入不同的数据源 | 支持从 es rest api 获取数据，并且写入 es |
| 数据缓冲       | 实现了简单的数据队列，支持重写             | 不支持缓冲                             |
| 数据处理       | 支持插件，支持定制开发                     | 内置插件，开发插件扩展（需要重启）     |
| 配置使用       | 增加了架构复杂度                           | 无需额外部署                           |

## Painless 脚本

支持有 java 的数据类型及 Java Api 子集

| 上下文               | 语法                   |
| -------------------- | ---------------------- |
| Ingestion            | ctx.field_name         |
| Update               | ctx.\_source.field_name |
| search & aggregation | doc[“field_name”]      |

# 数据建模

- Text
  - 用于全文本字段，文本会被 analyzer 分词
  - 默认不支持聚合分析及排序。需要设置 fielddata 为 true。
- keyword
  - 用于 id，枚举及不需要分词的文本
  - 适用于 filter（精确匹配），排序和聚合
- 设置多字段类型
  - 默认会为文本类型设置成 text，并且设置一个 keyword 字段
  - 在处理人类语言时，通过增加 “英文”，“拼音” 和 “标准” 分词器，提高搜索结构
- 枚举类型
  - 设置为 keywrod，即便是数字，可以获得更好的性能
- 更新频繁，聚合查询频繁的 keyword 类型字段
  - 将 eager_global_ordinals 设置为 true

>[!example]
>```http
// 对图书内容进行搜索，图书内容会导致 _source 内容过大
// es fetch 数据时还是会传输 _source 中的数据
// 解决方法
// 关闭 _source
// 将每个字段的 store 设置成 true，这样可以使得数据额外的存储在 es 中
PUT books
{
>	"mappings": {
>		"_source": {
>			"enabled": false
>		},
>		"properties": {
>			"author": {
>				"type": "keyword",
>				"store": true,
>			},
>			"cover_url": {
>				"type": "keyword",
>				"index": false,
>				"store": true
>			},
>			"description": {
>				"type": "text",
>				"store": true
>			},
>			"content": {
>				"type": "text",
>				"store": true,
>			},
>			"public_date": {
>				"type": "date",
>				"store": true
>			},
>			"title": {
>				"type": "text",
>				"fields": {
>					"keyword": {
>						"type": "keyword",
>						"ignore_above": 100
>					}
>				},
>				"store": true
>			}
>		}
>	}
>}
>
// 搜索时，不会显示 _source 字段，需要指定显示的数据
POST books/_search
> {
>	"stored_fields": ["title","author","public_date"],
>	"query": {
>		"match": {
>			"content": "searching",
>		}
>	},
>	"highlight": {
>		"fields": {
>			"content": {}
>		}
>	}
> }
> ```

- 避免 Null 值引起的聚合不准

- 为索引的 mapping 加入 meta 信息，同时可以考虑将 mapping 文件上传 git 管理

>[!example]
>  ```http
  PUT index
  {
  	"mappings": {
  		"_meta": {
  			"version": "1.0"
  		}
  	}	
  }
  >```
  

# 索引管理 API

- open/close index：索引关闭后无法进行读写，但是索引数据不会被删除
- shrink index：可以将索引的主分片数收缩到较小的值
- split index：可以扩大主分片个数
- rollover index：索引尺寸或者时间超过一定值后，创建新的
- rollup index：对数据进行处理后，重新写入，减少数据量