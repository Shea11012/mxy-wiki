---
date created: 2022-03-15 17:56
date modified: 2024-06-01 15:01
---

AR：分区的所有副本
ISR：已经达成一定同步的副本，可作为 leader 的候选
LEO：leader 节点将要写入的 offset
HW：所有 ISR 节点都达到的最高水位
LSO：最小的未提交事务的 msg offset
At Least Once：默认消费类型，消费了就标识一下，业务方自己做好去重
At Most Once：先提交 offset 再处理，重启后从最新的 offset 开始，最多就消费一次
Exactly Once：精确一次（有局限，kafka 实现的场景）：
- 幂等性保证 producer 单会话单分区消息的投递精准一次
- 事务保证跨多分区写入是原子
- stream 任务（从一个 topic 消费 map 到另一个 topic），使用 read-process-write 写法，确保精准一次（由 producer 对象来提交 consumer 的 offset）

# kafka 节点是 pull 还是 push

pull，pull 时 consumer 可以根据自己的能力按需拉取，如果是 push 可能导致大量数据推过来，打卦 consumer。pull 轮询也会导致资源浪费，所以可以配置 pull 一段时间，没有数据就一直等待。

# 如何保证消息不丢失

- producer 端：
	- ACKS=all，保证每个 ISR 中的节点都写入完成再确认
	- retries>1，多次重试
	- max.in.flight.requests.per.connection=1，在得到一个请求确认信号前不会发送下一个请求，避免重新发送消息时导致消息顺序混乱
- broker 端：
	- replica-factor=min.insync.replica+1，保证每个分区的备份
	- min.insync.replica>1，至少有这么多 replica 写入完成，broker 才认为消息写入成功
	- unclear.leader.election.enable=false，ISR 之外的不能竞选 leader
- consumer 端：
	- 需要先消费消息再手动提交 offset

# 保证消息不重复

- consumer：
	- 在设置了消费后提交 offset 后，仍然会有可能机器挂了没能提交上 offset 的情况。只能在业务上进行一些限制，如保证消息幂等、通过 db 主键来保证
- producer：
	- 开启幂等性，可以保证消息发送不重复，**幂等只能保证单会话，单分区幂等**
	- 开启事务，幂等只能单消息不重复，无法保证原子性，如果多个分区或多个 topic 需要事务来保证原子操作

# kafka 为什么不支持读写分离

kafka 为了避免数据不一致的问题，采用通过主节点来统一提供服务的方式。
不支持读写分离的原因：
- 场景不一致：读写分离是针对读操作负载很大，但写操作负载不高的场景。kafka 不适合这种场景。
- 延迟问题：kafka 通过 pull 方式来实现数据同步，因此 leader 与 follower 副本之间存在数据不一致的情况，如果允许 follower 提供读服务，就会带来消息滞后的问题。

## kafka 能否手动删除消息

kafka 存储日志结构中每一个分区副本都对应一个 log，log 又可以分为多个 logSegment，这样便于 kafka 对日志的清理操作。
- 普通消息：使用 kafka-delete-records 或调用 API `Admin.deleteRecords` 删除消息
- 设置 key 且参数 `cleanup.policy=delete/campact`，可以依靠 log cleaner 组件提供的功能删除该 key 消息
	- 日志删除，按照一定的保留策略直接删除不符合条件的日志分段
	- 日志压缩，针对每个消息的 key 进行整合，对于有相同 key 的不同 value 值，只保留最后一个版本
